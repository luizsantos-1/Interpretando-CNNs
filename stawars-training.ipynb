{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luizeduardosantos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/luizeduardosantos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/luizeduardosantos/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "d_shape = 256\n",
    "def pre_processing(d_shape = d_shape):\n",
    "\n",
    "    path = '/Users/luizeduardosantos/Documents/Turing/projeto-trainee-cv/'\n",
    "\n",
    "\n",
    "    images = {}\n",
    "    labels = {}\n",
    "    for part in [\"train\", \"validation\", \"test\"]:\n",
    "        Darth_images = np.array([cv2.imread(file) for file in glob.glob(path + part + \"/Darth Vader\" + '/*')])\n",
    "        Storm_images = np.array([cv2.imread(file) for file in glob.glob(path + part + \"/Stormtrooper\" + '/*')])\n",
    "        Yoda_images = np.array([cv2.imread(file) for file in glob.glob(path + part + \"/Yoda\" + '/*')])\n",
    "\n",
    "        labels_Darth = np.full((Darth_images.shape[0], 1), 0)\n",
    "        labels_Storm = np.full((Storm_images.shape[0], 1), 1)\n",
    "        labels_Yoda = np.full((Yoda_images.shape[0], 1), 2)\n",
    "\n",
    "        labels[part] = np.concatenate((labels_Darth,labels_Storm,labels_Yoda))\n",
    "\n",
    "        part_images = np.concatenate((Darth_images, Storm_images, Yoda_images))\n",
    "\n",
    "        resized_images = np.empty((part_images.shape[0],d_shape,d_shape,3), dtype=int)\n",
    "\n",
    "        for i in range (part_images.shape[0]):\n",
    "            resized_images[i] = cv2.resize(part_images[i],(d_shape,d_shape))\n",
    "\n",
    "        resized_images = resized_images/255.\n",
    "\n",
    "        images[part] = resized_images\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "images, labels = pre_processing()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 245, 245, 32)      13856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 122, 122, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 99, 99, 16)        294928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 49, 49, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 8)           294920    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 605,051\n",
      "Trainable params: 605,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(32, (12,12), activation='relu', input_shape=(256, 256 ,3)))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model2.add(layers.Conv2D(16, (24,24), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model2.add(layers.Conv2D(8, (48,48), activation='relu'))\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "model2.add(layers.Dense(32, activation= 'relu'))\n",
    "model2.add(layers.Dense(8, activation= 'relu'))\n",
    "model2.add(layers.Dense(3, activation= 'softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "23/23 [==============================] - 397s 17s/step - loss: 1.5655 - accuracy: 0.3456 - val_loss: 1.0684 - val_accuracy: 0.3770\n",
      "Epoch 2/9\n",
      "23/23 [==============================] - 404s 18s/step - loss: 1.0537 - accuracy: 0.4030 - val_loss: 1.0759 - val_accuracy: 0.3607\n",
      "Epoch 3/9\n",
      "23/23 [==============================] - 400s 17s/step - loss: 1.0359 - accuracy: 0.4139 - val_loss: 0.9802 - val_accuracy: 0.4699\n",
      "Epoch 4/9\n",
      "23/23 [==============================] - 461s 20s/step - loss: 0.9562 - accuracy: 0.5123 - val_loss: 0.9165 - val_accuracy: 0.5628\n",
      "Epoch 5/9\n",
      "11/23 [=============>................] - ETA: 3:25 - loss: 0.9082 - accuracy: 0.6009"
     ]
    }
   ],
   "source": [
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss= SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(x = images[\"train\"],y = labels[\"train\"], epochs=9, batch_size = 64,\n",
    "                    validation_data = (images[\"validation\"], labels[\"validation\"]), shuffle = True )\n",
    "\n",
    "                    \n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0c4c4d3179d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.evaluate(images[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/luizeduardosantos/Documents/Turing/Interpretando-CNNs/model2-files/assets\n"
     ]
    }
   ],
   "source": [
    "model2.save('/Users/luizeduardosantos/Documents/Turing/Interpretando-CNNs/model2-files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d954621e7fe161d292da133f3bc2fe0b96b122d86b3622a4127a8e572f09d5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
